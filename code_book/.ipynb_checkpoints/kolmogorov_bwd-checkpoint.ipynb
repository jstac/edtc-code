{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolmogorov Backward Equation\n",
    "\n",
    "## Overview \n",
    "\n",
    "As models become more complex, deriving analytical representations of the\n",
    "transition semigroup $(P_t)$ becomes harder.\n",
    "\n",
    "This is analogous to the idea that solutions to continuous time models often\n",
    "lack analytical solutions.\n",
    "\n",
    "For example, when studying deterministic paths in continuous time,\n",
    "infinitesimal descriptions (ODEs and PDEs) are often more intuitive and easier\n",
    "to write down than the associated solutions.\n",
    "\n",
    "(This is one of the shining insights of mathematics, beginning with the work\n",
    "of great scientists such as Isaac Newton.)\n",
    "\n",
    "We will see in this lecture that the same is true for continuous time Markov\n",
    "chains.\n",
    "\n",
    "To help us focus on intuition in this lecture, rather than technicalities, the state space is assumed to be finite, with $|S|=n$.\n",
    "\n",
    "Later we will investigate the case where $|S| = \\infty$.\n",
    "\n",
    "We will use the following imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import quantecon as qe\n",
    "from numba import njit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Dependent Jump Intensities\n",
    "\n",
    "As we have seen, continuous time Markov chains jump between states, and hence can \n",
    "have the form\n",
    "\n",
    "$$\n",
    "    X_t = \\sum_{k \\geq 0} Y_k \\mathbb 1\\{J_k \\leq t < J_{k+1}\\}\n",
    "    \\qquad (t \\geq 0)\n",
    "$$ \n",
    "\n",
    "where $(J_k)$ are jump times and $(Y_k)$ are the states at each jump.\n",
    "\n",
    "(We are assuming that $J_k \\to \\infty$ with probability one, so that $X_t$ is well\n",
    "defined for all $t \\geq 0$, but this is always true for when holding times are exponential and the state space is finite.)\n",
    "\n",
    "In the {doc}`previous lecture <markov_prop>`, \n",
    "\n",
    "* the sequence $(Y_k)$ was drawn from a Markov kernel $K$ and called the embedded jump chain, while\n",
    "* the holding times $W_k := J_k - J_{k-1}$ were IID and Exp$(\\lambda)$ for some\n",
    "constant jump intensity $\\lambda$.\n",
    "\n",
    "In this lecture, we will generalize by allowing the jump intensity to vary\n",
    "with the state.\n",
    "\n",
    "This difference sounds minor but in fact it will allow us to reach full generality\n",
    "in our description of continuous time Markov chains, as\n",
    "clarified below.\n",
    "\n",
    "### Motivation\n",
    "\n",
    "As a motivating example, recall {ref}`the inventory model <inventory_dynam>`,\n",
    "where we assumed that the wait time for the next customer was equal\n",
    "to the wait time for new inventory.\n",
    "\n",
    "This assumption was made purely for convenience and seems unlikely to hold true.\n",
    "\n",
    "When we relax it, the jump intensities depend on the state.\n",
    "\n",
    "\n",
    "### Algorithmic Construction\n",
    "\n",
    "We start with two primitives\n",
    "\n",
    "1. A Markov kernel $K$ on $S$ satisfying $K(x, x) = 0$ for all $x \\in S$\n",
    "   and\n",
    "1. A function $\\lambda$ mapping $S$ to $(0, \\infty)$.\n",
    "\n",
    "The process $(X_t)$ \n",
    "\n",
    "* starts at state $x$, \n",
    "* waits there for an exponential time $W$ with rate $\\lambda(x)$ and then\n",
    "* updates to a new state $y$ drawn from $K(x, \\cdot)$.\n",
    "\n",
    "Now we take $y$ as the new state for the process and repeat.\n",
    "\n",
    "More explicitly, assuming initial condition $\\psi$, we\n",
    "\n",
    "1. draw $Y_0$ from $\\psi$, set $J_0 = 0$ and $n=1$.\n",
    "1. Draw $W_n$ independently from Exp$(\\lambda(Y_{n-1}))$.\n",
    "1. Set $J_n = J_{n-1} + W_n$.\n",
    "1. Set $X_t = Y_{n-1}$ for $t$ in $[J_{n-1}, J_n)$.\n",
    "1. Draw $Y_n$ from $K(Y_{n-1}, \\cdot)$.\n",
    "1. Set $n = n+1$ and go to step 2.\n",
    "\n",
    "The sequence $(W_n)$ is drawn as an IID sequence and $(W_n)$ and $(Y_n)$ are\n",
    "drawn independently.\n",
    "\n",
    "The restriction $K(x,x) = 0$ for all $x$ implies that $(X_t)$ actually jumps at each jump time.\n",
    "\n",
    "\n",
    "\n",
    "## Computing the Semigroup\n",
    "\n",
    "For the jump process $(X_t)$ with time varying intensities described in the\n",
    "algorithm just given, calculating the transition semigroup is not a trivial exercise.\n",
    "\n",
    "The approach we adopt is\n",
    "\n",
    "1. use probabilistic reasoning to obtain an integral equation that the\n",
    "   semigroup must satisfy.\n",
    "1. Convert the integral equation into a differential equation that is easier\n",
    "   to work with.\n",
    "1. Solve this differential equation to obtain the transition semigroup $(P_t)$.\n",
    "\n",
    "\n",
    "The differential equation in question has a special name:  the Kolmogorov backward equation.\n",
    "\n",
    "\n",
    "### An Integral Equation\n",
    "\n",
    "The integral equation referred to above is\n",
    "\n",
    "$$\n",
    "    P_t(x, y) = e^{-t \\lambda(x)} I(x, y)\n",
    "    + \\lambda(x) \n",
    "      \\int_0^t (K P_{t-\\tau})(x, y) e^{- \\tau \\lambda(x)} d \\tau\n",
    "$$ (kbinteg)\n",
    "\n",
    "which, we claim, holds for all $t \\geq 0$ and $x, y$ in $S$.\n",
    "\n",
    "Here $(P_t)$ is the transition semigroup of $(X_t)$, the process constructed\n",
    "algorithmically above, while \n",
    "$K P_{t-\\tau}$ is the product of two Markov kernels as previously\n",
    "defined.\n",
    "\n",
    "Let's see why {eq}`kbinteg` holds.\n",
    "\n",
    "Conditioning implicitly on $X_0 = x$, the semigroup $(P_t)$ must satisfy \n",
    "\n",
    "$$\n",
    "    P_t(x, y) \n",
    "    = \\mathbb P\\{X_t = y\\}\n",
    "    = \\mathbb P\\{X_t = y, \\; J_1 > t \\}\n",
    "        + \\mathbb P\\{X_t = y, \\; J_1 \\leq t \\}\n",
    "$$ (pt_split)\n",
    "\n",
    "\n",
    "Regarding the first term on the right hand side of {eq}`pt_split`, we have \n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_t = y, \\; J_1 > t \\}\n",
    "        = I(x, y) P\\{J_1 > t \\}\n",
    "        = I(x, y) e^{- t \\lambda(x)}\n",
    "$$ (pt_first)\n",
    "\n",
    "where $I(x, y) = \\mathbb 1\\{x = y\\}$.\n",
    "\n",
    "For the second term on the right hand side of {eq}`pt_split`, we have \n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_t = y, \\; J_1 > t \\}\n",
    "    = \\mathbb E \n",
    "        \\left[\n",
    "            \\mathbb 1\\{J_1 > t\\} \\mathbb P\\{X_t = y \\,|\\, W_1, Y_1\\}\n",
    "        \\right]\n",
    "    = \\mathbb E \n",
    "        \\left[\n",
    "            \\mathbb 1\\{J_1 > t\\} P_{t - J_1} (Y_1, y) \n",
    "        \\right]\n",
    "$$\n",
    "\n",
    "Evaluating the expectation and using the independence of $J_1$ and $Y_1$, this becomes\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbb P\\{X_t = y, \\; J_1 > t \\}\n",
    "    & = \\int_0^\\infty\n",
    "            \\mathbb 1\\{\\tau > t\\}\n",
    "            \\sum_z K(x, z) P_{t - \\tau} (z, y)  \\lambda(x) e^{-\\tau \\lambda(x)} \n",
    "            d \\tau\n",
    "        \\\\\n",
    "    & = \\lambda(x)\n",
    "            \\int_0^t\n",
    "            \\sum_z K(x, z) P_{t - \\tau} (z, y)  e^{-\\tau \\lambda(x)} \n",
    "            d \\tau\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Combining this result with {eq}`pt_split` and {eq}`pt_first` gives\n",
    "{eq}`kbinteg`.\n",
    "\n",
    "\n",
    "\n",
    "### Kolmogorov's Differential Equation\n",
    "\n",
    "We have now confirmed that the semigroup $(P_t)$ associated with the process\n",
    "$(X_t)$ should satisfy {eq}`kbinteg`.\n",
    "\n",
    "\n",
    "Equation {eq}`kbinteg` is important but we can simplify it further without\n",
    "losing information by taking the time derivative.\n",
    "\n",
    "Doing so leads to the **Kolmogorov backward equation**, which is, for this\n",
    "model\n",
    "\n",
    "$$\n",
    "    P'_t = Q P_t \n",
    "    \\quad \\text{where } \\;\n",
    "    Q(x, y) := \\lambda(x) (K(x, y) - I(x, y))\n",
    "$$ (kolbackeq)\n",
    "\n",
    "The derivative on the left hand side of {eq}`kolbackeq` is taken element by\n",
    "element, with respect to $t$, so that\n",
    "\n",
    "$$\n",
    "    P'_t(x, y) = \\left( \\frac{d}{dt} P_t(x, y) \\right)\n",
    "    \\qquad ((x, y) \\in S \\times S)\n",
    "$$\n",
    "\n",
    "The proof that differentiating {eq}`kbinteg` yields {eq}`kolbackeq` is an\n",
    "important exercise (see below).\n",
    "\n",
    "\n",
    "\n",
    "### Exponential Solution\n",
    "\n",
    "The Kolmogorov backward equation is a matrix-valued differential equation.\n",
    "\n",
    "Recall that, for a scalar differential equation $y'_t = a y_t$ with constant\n",
    "$a$ and initial condition $y_0$, the solution is $y_t = e^{ta} y_0$.\n",
    "\n",
    "This, along with $P_0 = I$, encourages us to guess that the solution to\n",
    "Kolmogorov's backward equation {eq}`kolbackeq` is\n",
    "\n",
    "$$\n",
    "    P_t = e^{t Q} \n",
    "$$ (expsol)\n",
    "\n",
    "where the right hand side is the [matrix exponential](https://en.wikipedia.org/wiki/Matrix_exponential), with definition \n",
    "\n",
    "$$\n",
    "    e^{tQ} \n",
    "    = \\sum_{k \\geq 0} \\frac{1}{k!} (tQ)^k\n",
    "    = I + tQ + \\frac{t^2}{2!} Q^2 + \\cdots\n",
    "$$ (expofun)\n",
    "\n",
    "Working element by element, it is not difficult to confirm that \n",
    "the derivative of the exponential function $t \\mapsto e^{tQ}$ is\n",
    "\n",
    "$$\n",
    "    \\frac{d}{dt} e^{t Q} = Q e^{t Q} = e^{t Q} Q\n",
    "$$ (expoderiv)\n",
    "\n",
    "Hence, differentiating {eq}`expsol` gives $P'_t = Q e^{t Q} = Q P_t$, which\n",
    "convinces us that the exponential solution satisfies {eq}`kolbackeq`. \n",
    "\n",
    "Notice that our solution\n",
    "\n",
    "$$\n",
    "    P_t = e^{t Q} \n",
    "    \\quad \\text{where } \\;\n",
    "    Q(x, y) := \\lambda(x) (K(x, y) - I(x, y))\n",
    "$$  (psolq)\n",
    "\n",
    "for the semigroup of the jump process $(X_t)$ associated with the jump kernel\n",
    "$K$ and the jump intensity function $\\lambda \\colon S \\to (0, \\infty)$ is\n",
    "consistent with our earlier result.\n",
    "\n",
    "In particular, we {ref}`showed <consjumptransemi>` that, for the model with\n",
    "constant jump intensity $\\lambda$, we have $P_t = e^{t \\lambda (K - I)}$.\n",
    "\n",
    "This is obviously a special case of {eq}`psolq`.\n",
    "\n",
    "\n",
    "\n",
    "## Properties of the Solution\n",
    "\n",
    "Let's investigate further the properties of the exponential solution.\n",
    "\n",
    "### Checking the Transition Semigroup Properties\n",
    "\n",
    "While we have confirmed that $(P_t)$ defined by $P_t = e^{t Q}$ solves the\n",
    "Kolmogorov backward equation, we have not yet shown that this solution is in\n",
    "fact a transition semigroup.\n",
    "\n",
    "Let's now tie up this loose end.\n",
    "\n",
    "First\n",
    "\n",
    "$$\n",
    "    \\sum_y Q(x, y) \n",
    "    = \\lambda(x) \\sum_y (K(x, y) - I(x, y))\n",
    "    = 0\n",
    "$$\n",
    "\n",
    "Hence, if $1$ is a column vector of ones, then $Q 1$ is the\n",
    "zero vector.\n",
    "\n",
    "This implies that $Q^k 1 = 0$ for all $k$ and, as a result, for any $t \\geq\n",
    "0$,\n",
    "\n",
    "$$\n",
    "    P_t 1\n",
    "    = e^{tQ} 1\n",
    "    = I1 + tQ1 + \\frac{t^2}{2!} Q^2 1 + \\cdots\n",
    "    = I1 = 1\n",
    "$$\n",
    "\n",
    "We have now shown that each $P_t$ has unit row sums, so all that remains to\n",
    "check is positivity of all elements (which can easily fail for matrix\n",
    "exponentials).\n",
    "\n",
    "To this end, adopting an argument from {cite}`stroock2013introduction`, we\n",
    "set $m := \\max_x \\lambda(x)$ and $\\hat P := I + Q / m$.\n",
    "\n",
    "It is not difficult to check that $\\hat P$ is a Markov matrix and $Q = m( \\hat\n",
    "P - I)$.\n",
    "\n",
    "Recalling that, for matrix exponentials, $e^{A+B} = e^A e^B$ whenever $AB =\n",
    "BA$, we have\n",
    "\n",
    "$$\n",
    "    e^{tQ} \n",
    "    = e^{tm (\\hat P - I)} \n",
    "    = e^{-tm I} e^{tm \\hat P}\n",
    "    = e^{-tm} \n",
    "        \\left( \n",
    "            I + tm \\hat P + \\frac{(tm)^2}{2!} \\hat P^2 + \\cdots\n",
    "        \\right)\n",
    "$$\n",
    "\n",
    "It is clear from this representation that all entries of $e^{tQ}$ are\n",
    "nonnegative.\n",
    "\n",
    "We can now be reassured that our solution to the Kolmogorov backward equation\n",
    "is indeed a transition semigroup.\n",
    "\n",
    "\n",
    "### Uniqueness\n",
    "\n",
    "Might there be another, entirely different transition semigroup that also\n",
    "satisfies the Kolmogorov backward equation?\n",
    "\n",
    "The answer is no --- linear ODEs with constant coefficients and fixed initial\n",
    "conditions (in this case $P_0 = I$) have unique solutions.\n",
    "\n",
    "In fact it's not hard to supply a proof --- see the exercises.\n",
    "\n",
    "\n",
    "\n",
    "## Application: The Inventory Model\n",
    "\n",
    "Let us look at a modified version of the inventory model where jump\n",
    "intensities depend on the state.\n",
    "\n",
    "In particular, the wait time for new inventory will now be exponential at rate\n",
    "$\\gamma$.\n",
    "\n",
    "The arrival rate for customers will still be denoted by $\\lambda$ and allowed\n",
    "to differ from $\\gamma$.\n",
    "\n",
    "For parameters we take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "α = 0.6\n",
    "λ = 0.5\n",
    "γ = 0.1\n",
    "b = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our plan is to investigate the distribution $\\psi_T$ of $X_T$ at $T=30$.\n",
    "\n",
    "We will do this by simulating many independent draws of $X_T$ and\n",
    "histogramming them.\n",
    "\n",
    "(In the exercises you are asked to calculate $\\psi_T$ a different way, via\n",
    "{eq}`psolq`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def draw_X(T, X_0, max_iter=5000):\n",
    "    \"\"\"\n",
    "    Generate one draw of X_T given X_0.\n",
    "    \"\"\"\n",
    "\n",
    "    J, Y = 0, X_0\n",
    "    m = 0\n",
    "\n",
    "    while m < max_iter:\n",
    "        s = 1/γ if Y == 0 else 1/λ\n",
    "        W = np.random.exponential(scale=s)  # W ~ E(λ)\n",
    "        J += W\n",
    "        if J >= T:\n",
    "            return Y\n",
    "        # Otherwise update Y\n",
    "        if Y == 0:\n",
    "            Y = b\n",
    "        else:\n",
    "            U = np.random.geometric(α)\n",
    "            Y = Y - min(Y, U)\n",
    "        m += 1\n",
    "\n",
    "\n",
    "\n",
    "@njit\n",
    "def independent_draws(T=10, num_draws=100):\n",
    "\n",
    "    draws = np.empty(num_draws, dtype=np.int64)\n",
    "\n",
    "    for i in range(num_draws):\n",
    "        X_0 = np.random.binomial(b+1, 0.25)\n",
    "        draws[i] = draw_X(T, X_0)\n",
    "\n",
    "    return draws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOk0lEQVR4nO3dfYxld13H8feHXRsFJKg7Pu0WdpFCbaRIs5YioJUH04K6gBhasTzb1FCelEgxRmP4A4gGkVjZNLU8SKUUqLrUlUoqBLGAO4Xa0kJ1U5AOBToFlQcNZcvXP+4pXMfZuXe3d+Z2vn2/ks3c8zDn/k53+96zZ+b8JlWFJGnzu9e8ByBJmg2DLklNGHRJasKgS1ITBl2Smtg6rzfetm1b7dy5c15vL0mb0tVXX31bVS2stm1uQd+5cyeLi4vzentJ2pSS/PvhtnnLRZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpqY25Oid8UrL7tu3Y796qc9bN2OLUnrySt0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDUxVdCTnJbkxiQHk5y3xn4/leSOJE+f3RAlSdOYGPQkW4DzgdOBE4Azk5xwmP1eC1wx60FKkiab5gr9ZOBgVd1UVbcDlwB7VtnvRcC7gVtnOD5J0pSmCfp24Oax5aVh3bcl2Q48Fdi71oGSnJ1kMcni8vLykY5VkrSGaYKeVdbViuXXA6+oqjvWOlBVXVBVu6tq98LCwrRjlCRNYZqfKboEHDu2vAO4ZcU+u4FLkgBsA56U5FBV/fVMRilJmmiaoB8AjkuyC/gccAbwq+M7VNWuO18neTNwuTGXpI01MehVdSjJuYy+e2ULcFFVXZ/knGH7mvfNJUkbY5ordKpqP7B/xbpVQ15Vz7nrw5IkHSmfFJWkJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSE1MFPclpSW5McjDJeats35Pk2iTXJFlM8pjZD1WStJatk3ZIsgU4H3gisAQcSLKvqm4Y2+1KYF9VVZITgUuB49djwJKk1U1zhX4ycLCqbqqq24FLgD3jO1TV16qqhsX7AIUkaUNNE/TtwM1jy0vDuv8jyVOTfAr4W+B5qx0oydnDLZnF5eXloxmvJOkwpgl6Vln3/67Aq+qvqup44CnAq1Y7UFVdUFW7q2r3wsLCkY1UkrSmaYK+BBw7trwDuOVwO1fVB4EfS7LtLo5NknQEpgn6AeC4JLuSHAOcAewb3yHJg5NkeH0ScAzwpVkPVpJ0eBO/y6WqDiU5F7gC2AJcVFXXJzln2L4X+GXgWUm+CfwP8IyxL5JKkjbAxKADVNV+YP+KdXvHXr8WeO1shyZJOhI+KSpJTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJqYKepLTktyY5GCS81bZ/swk1w6/rkry8NkPVZK0lolBT7IFOB84HTgBODPJCSt2+zTws1V1IvAq4IJZD1SStLZprtBPBg5W1U1VdTtwCbBnfIequqqq/mNY/AiwY7bDlCRNMk3QtwM3jy0vDesO5/nA3622IcnZSRaTLC4vL08/SknSRNMEPausq1V3TH6OUdBfsdr2qrqgqnZX1e6FhYXpRylJmmjrFPssAceOLe8Ablm5U5ITgQuB06vqS7MZniRpWtNcoR8AjkuyK8kxwBnAvvEdkjwAuAw4q6r+dfbDlCRNMvEKvaoOJTkXuALYAlxUVdcnOWfYvhf4PeAHgD9LAnCoqnav37AlSStNc8uFqtoP7F+xbu/Y6xcAL5jt0CRJR8InRSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxFRBT3JakhuTHExy3irbj0/y4STfSPLy2Q9TkjTJ1kk7JNkCnA88EVgCDiTZV1U3jO32ZeDFwFPWZZSSpImmuUI/GThYVTdV1e3AJcCe8R2q6taqOgB8cx3GKEmawjRB3w7cPLa8NKyTJN2NTBP0rLKujubNkpydZDHJ4vLy8tEcQpJ0GNMEfQk4dmx5B3DL0bxZVV1QVburavfCwsLRHEKSdBjTBP0AcFySXUmOAc4A9q3vsCRJR2rid7lU1aEk5wJXAFuAi6rq+iTnDNv3JvlhYBG4H/CtJC8FTqiqr6zj2CVJYyYGHaCq9gP7V6zbO/b6C4xuxUiS5sQnRSWpiamu0CXpnuaVl123bsd+9dMeti7H9Qpdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU04fe6U1msqzcNNo7nR7ydp8zPomouNnmt6HnNbd78I6PJ+a73nZmPQBfg/i9SB99AlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSE1MFPclpSW5McjDJeatsT5I3DNuvTXLS7IcqSVrLxKAn2QKcD5wOnACcmeSEFbudDhw3/DobeOOMxylJmmCaK/STgYNVdVNV3Q5cAuxZsc8e4K018hHg/kl+ZMZjlSStIVW19g7J04HTquoFw/JZwCOr6tyxfS4HXlNVHxqWrwReUVWLK451NqMreICHAjfO6kQm2AbctkHvNQ+e3+bX/Ry7nx9s3Dk+sKoWVtuwdYpPzirrVv4tMM0+VNUFwAVTvOdMJVmsqt0b/b4bxfPb/LqfY/fzg7vHOU5zy2UJOHZseQdwy1HsI0laR9ME/QBwXJJdSY4BzgD2rdhnH/Cs4btdTgH+q6o+P+OxSpLWMPGWS1UdSnIucAWwBbioqq5Pcs6wfS+wH3gScBD4b+C56zfko7Lht3k2mOe3+XU/x+7nB3eDc5z4RVFJ0ubgk6KS1IRBl6QmWgd90pQFm12SY5O8P8knk1yf5CXzHtN6SLIlyceH5x1aSXL/JO9K8qnh9/FR8x7TrCV52fDn8xNJ3p7ku+c9prsiyUVJbk3yibF135/kfUn+bfj4ffMYW9ugTzllwWZ3CPitqvpx4BTghQ3PEeAlwCfnPYh18ifAe6vqeODhNDvPJNuBFwO7q+onGH1jxRnzHdVd9mbgtBXrzgOurKrjgCuH5Q3XNuhMN2XBplZVn6+qjw2vv8ooBtvnO6rZSrIDeDJw4bzHMmtJ7gf8DPDnAFV1e1X953xHtS62At+TZCtwbzb5MypV9UHgyytW7wHeMrx+C/CUDR3UoHPQtwM3jy0v0Sx245LsBB4BfHS+I5m51wO/DXxr3gNZBw8CloE3DbeULkxyn3kPapaq6nPAHwGfBT7P6BmVv5/vqNbFD9357M3w8QfnMYjOQZ9qOoIOktwXeDfw0qr6yrzHMytJfgG4taqunvdY1slW4CTgjVX1CODrzOmf6utluJe8B9gF/ChwnyS/Nt9R9dU56PeI6QiSfBejmF9cVZfNezwz9mjgl5J8htEts8cledt8hzRTS8BSVd35r6p3MQp8J08APl1Vy1X1TeAy4KfnPKb18MU7Z5gdPt46j0F0Dvo0UxZsaknC6P7rJ6vqdfMez6xV1SurakdV7WT0+/cPVdXm6q6qvgDcnOShw6rHAzfMcUjr4bPAKUnuPfx5fTzNvvA72Ac8e3j9bOBv5jGIaWZb3JQON2XBnIc1a48GzgKuS3LNsO53qmr/HMekI/Mi4OLhouMm7n7TZtwlVfXRJO8CPsbou7I+zt3gEfm7IsnbgVOBbUmWgN8HXgNcmuT5jP4S+5W5jM1H/yWph863XCTpHsWgS1ITBl2SmjDoktSEQZekJgy6Nq0kV23ge52apOMDMWrEoGvTqqqNDOypHOETjsNkVNKGMejatJJ8bfh4apIPjM0rfvHwA8tPT3Lp2P6nJnnP8Prnk3w4yceSvHOYD4ckn0nyB8P665IcP0x8dg7wsiTXJHlskgcmuTLJtcPHBwyf/+Ykr0vyfuAPh/mxF4Zt9xrm5t+2of+hdI9h0NXFI4CXMpr7/kGMnqJ9H6PHzu+cwfAZwDuGoP4u8ISqOglYBH5z7Fi3DevfCLy8qj4D7AX+uKp+sqr+EfhT4K1VdSJwMfCGsc9/yHDslwFvA545rH8C8C9VddtsT10aMejq4p+raqmqvgVcA+ysqkPAe4FfHG5/PJnRHBunMAr/Pw1TJjwbeODYse6c5OxqYOdh3u9RwF8Or/8CeMzYtndW1R3D64uAZw2vnwe86ehOT5rMe3zq4htjr+/gO3+23wG8kNEPJDhQVV8dJol6X1WdOeFY48eZZHwOja9/e2XVzUm+mORxwCP5ztW6NHNeoau7DzCakvbXGcUd4CPAo5M8GGCYCfAhE47zVeB7x5av4js/Su2ZwIfW+NwLGd16uXTsyl2aOYOu1oaAXs7oZ8tePqxbBp4DvD3JtYwCf/yEQ70HeOqdXxRl9HMynzt8/lmMfu7p4ewD7ou3W7TOnG1RWmdJdjP6gupj5z0W9eY9dGkdJTkP+A28d64N4BW6JDXhPXRJasKgS1ITBl2SmjDoktSEQZekJv4XwG2jrmSZsrwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 30\n",
    "n = b + 1 \n",
    "draws = independent_draws(T, num_draws=100_000)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(range(n), [np.mean(draws == i) for i in range(n)], width=0.8, alpha=0.6)\n",
    "ax.set(xlabel=\"inventory\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " exponential representation of semigroup to push densities forward.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Ex: Use algo to simulate forward to time $t$.  Histogram.  Compare.\n",
    "\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Prove that differentiating {eq}`kbinteg` at each $(x, y)$ yields {eq}`kolbackeq`.\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "We claimed above that the solution $P_t = e^{t Q}$ is the unique\n",
    "transition semigroup satisfying the backward equation $P'_t = Q P_t$.\n",
    "\n",
    "Try to supply a proof.\n",
    "\n",
    "(This is not an easy exercise but worth thinking about in any case.)\n",
    "\n",
    "### Solution to Exercise 2\n",
    "\n",
    "Here is one proof of uniqueness.\n",
    "\n",
    "Suppose that $(\\hat P_t)$ is another transition semigroup satisfying \n",
    "$P'_t = Q P_t$.\n",
    "\n",
    "Fix $t > 0$ and let $V_s$ be defined by $V_s = P_s \\hat P_{t-s}$ for all $s\n",
    "\\geq 0$.\n",
    "\n",
    "Note that $V_0 = \\hat P_t$ and $V_t = P_t$.\n",
    "\n",
    "Note also that $s \\mapsto V_s$ is differentiable, with derivative\n",
    "\n",
    "$$\n",
    "    V'_s \n",
    "    = P'_s \\hat P_{t-s} - P_s \\hat P'_{t-s}\n",
    "    = P_s Q \\hat P_{t-s} - P_s Q \\hat P_{t-s}\n",
    "    = 0\n",
    "$$\n",
    "\n",
    "where, in the second last equality, we used {eq}`expoderiv`.\n",
    "\n",
    "\n",
    "Hence $V_s$ is constant, so our previous observations $V_0 = \\hat P_t$ and $V_t = P_t$\n",
    "now yield $\\hat P_t = P_t$.\n",
    "\n",
    "Since $t$ was arbitrary, the proof is now done.\n",
    "\n",
    "\n",
    "\n",
    "## Solutions\n",
    "\n",
    "### Solution to Exercise 1\n",
    "\n",
    "One can easily verify that, when $f$ is a differentiable function and $\\alpha >\n",
    "0$, we have\n",
    "\n",
    "$$\n",
    "    g(t) = e^{- t \\alpha} f(t)\n",
    "    \\quad \\implies \\quad\n",
    "    g'(t) = e^{- t \\alpha} f'(t) - \\alpha g(t)\n",
    "$$ (gdiff)\n",
    "\n",
    "Note also that, with the change of variable $s = t - \\tau$, we can rewrite\n",
    "{eq}`kbinteg` as\n",
    "\n",
    "$$\n",
    "    P_t(x, y) = \n",
    "    e^{-t \\lambda(x)} \n",
    "    \\left\\{ \n",
    "        I(x, y)\n",
    "        + \\lambda(x) \n",
    "        \\int_0^t (K P_s)(x, y) e^{s \\lambda(x)} d s\n",
    "    \\right\\}\n",
    "$$ (kbinteg2)\n",
    "\n",
    "Applying {eq}`gdiff` yields\n",
    "\n",
    "$$\n",
    "    P'_t(x, y) \n",
    "    = e^{-t \\lambda(x)} \n",
    "        \\left\\{ \n",
    "             \\lambda(x) \n",
    "             (K P_t)(x, y) e^{t \\lambda(x)} \n",
    "        \\right\\}\n",
    "        - \\lambda(x) P_t(x, y)\n",
    "$$\n",
    "\n",
    "After minor rearrangements this becomes\n",
    "\n",
    "$$\n",
    "    P'_t(x, y) \n",
    "    = \\lambda(x) [ (K - I)  P_t](x, y) \n",
    "$$\n",
    "\n",
    "which is identical to {eq}`kolbackeq`."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

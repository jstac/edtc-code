{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Markov Property \n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "A continuous time stochastic process is said to have the Markov property if\n",
    "that the past and future are independent given the current state.\n",
    "\n",
    "(A more formal definition is provide below.)\n",
    "\n",
    "As we will see, the Markov property imposes a great deal of structure on\n",
    "continuous time processes.\n",
    "\n",
    "This structure leads to an elegant and powerful collection of results on\n",
    "evolution and dynamics.\n",
    "\n",
    "At the same time, the Markov property is general enough to cover many applied\n",
    "problems, as described in {doc}`the introduction <intro>`.\n",
    "\n",
    "\n",
    "\n",
    "### Setting\n",
    "\n",
    "In this lecture and much of what follows, the state space where dynamics\n",
    "evolve will be a [countable set](https://en.wikipedia.org/wiki/Countable_set),\n",
    "denoted henceforth by $S$, with typical elements $x, y$.\n",
    "\n",
    "(Note that \"countable\" is understood to include finite.)\n",
    "\n",
    "Regarding notation, in what follows, $\\sum_{x \\in S}$ is abbreviated to\n",
    "$\\sum_x$, the supremum $\\sup_{x \\in S}$ is abbreviated to $\\sup_x$ and so on.\n",
    "\n",
    "A **distribution** on $S$ is a function $\\phi$ from $S$ to $\\mathbb R_+$ with\n",
    "$\\sum_x \\phi(x) = 1$.\n",
    "\n",
    "Let $\\mathcal D$ denote the set of all distributions on $S$.\n",
    "\n",
    "In expressions involving matrix algebra, we **always treat distributions as row\n",
    "vectors**.\n",
    "\n",
    "We will use the following imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import quantecon as qe\n",
    "from numba import njit\n",
    "\n",
    "from scipy.linalg import expm\n",
    "from scipy.stats import binom\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Processes\n",
    "\n",
    "We now introduce the definition of Markov processes, first reviewing the\n",
    "discrete case and then shifting to continuous time.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Discrete Time, Finite State \n",
    "\n",
    "The simplest Markov processes are those with a discrete time parameter and finite state space.\n",
    "\n",
    "Assume for now that $S$ has $n$ elements and let $P$ be a Markov matrix (i.e., nonnegative with unit row sums) of size $n \\times n$.\n",
    "\n",
    "We write $P(x, y)$ for a typical element of $P$.\n",
    "\n",
    "(Most of the time, this is more convenient than using symbols such as $P_{ij}$, and it aligns better with the infinite state case.)\n",
    "\n",
    "In applications, $P(x, y)$ represents the probability of transitioning from $x$ to\n",
    "$y$ in one step.\n",
    "\n",
    "#### Markov Chains\n",
    "\n",
    "A Markov chain $(X_t)_{t \\in \\mathbb Z_+}$ on finite set $S$ with Markov matrix $P$ is a\n",
    "sequence of random variables satisfying \n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_{t+1} = y \\,|\\, X_0, X_1, \\ldots, X_t \\} = P (X_t, y)\n",
    "$$ (markovpropd)\n",
    "\n",
    "with probability one for all $y \\in S$ and any $t \\in \\mathbb Z_+$.\n",
    "\n",
    "In addition to connecting probabilities to the Markov matrix,\n",
    "{eq}`markovpropd` says that the process depends on its history only through\n",
    "the current state.\n",
    "\n",
    "We [recall that](https://python.quantecon.org/finite_markov.html), if $X_t$\n",
    "has distribution $\\psi$, then $X_{t+1}$ has distribution $\\psi P$.\n",
    "\n",
    "Since $\\psi$ is understood as a row vector, the meaning is\n",
    "\n",
    "$$\n",
    "    (\\psi P)(y) = \\sum_x \\psi(x) P(x, y) \n",
    "    \\qquad (y \\in S)\n",
    "$$ (update_rule)\n",
    "\n",
    "(jdfin)=\n",
    "#### The Joint Distribution\n",
    "\n",
    "In general, for given Markov matrix $P$, there can be many Markov chains\n",
    "$(X_t)$ that satisfy {eq}`markovpropd`.\n",
    "\n",
    "This is due to the more general observation that, for a given distribution\n",
    "$\\phi$, we can construct many random variables having distribution $\\phi$.\n",
    "\n",
    "(The exercises below ask for one example.)\n",
    "\n",
    "Hence $P$ is, in a sense, a more primitive object than $(X_t)$.\n",
    "\n",
    "There is another way to see the fundamental importance of $P$: by constructing the joint distribution.\n",
    "\n",
    "Consider the infinite sequence space $S^\\infty := S \\times S \\times \\cdots$.\n",
    "\n",
    "Together with an initial condition $\\psi \\in\n",
    "\\mathcal D$, a Markov matrix $P$ defines a distribution $\\mathbf P_\\psi$\n",
    "over $S^\\infty$ such that any\n",
    "Markov chain $(X_t)$ satisfying {eq}`markovpropd` and $X_0 \\sim \\psi$ has\n",
    "$\\mathbf P_\\psi$ as its joint distribution.\n",
    "\n",
    "The last statement is equivalent to \n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{ X_{t_1} = y_{t_1}, \\ldots, X_{t_k} = y_{t_k} \\}\n",
    "    =\n",
    "    \\mathbf P_\\psi\\{ (x_t) \\in S^\\infty \\,:\\, \n",
    "        x_{t_i} = y_{t_i} \\text{ for } i = 1, \\ldots m\\}\n",
    "$$ (jointdeq)\n",
    "\n",
    "for any $m$ positive integers $t_i$ and $m$ elements  $y_{t_i}$ of the state space $S$.\n",
    "\n",
    "\n",
    "(Joint distributions of discrete time processes\n",
    "are uniquely defined by their values at finite collections of times in the sense of\n",
    "{eq}`jointdeq` --- see, for example, Theorem 7.2 of {cite}`walsh2012knowing`.)\n",
    "\n",
    "\n",
    "To construct the joint distribution over $S^\\infty$, one first constructs a\n",
    "finite dimensional version over the Cartiesian product $S^{n+1}$\n",
    "via\n",
    "\n",
    "$$\n",
    "    \\mathbf P_\\psi^n(x_0, x_1, \\ldots, x_n)\n",
    "        = \\psi(x_0)\n",
    "        P(x_0, x_1)\n",
    "        \\times \\cdots \\times\n",
    "        P(x_{n-1}, x_n)\n",
    "$$ (mathjointd)\n",
    "\n",
    "Then one shows that for any Markov chain $(X_t)$ satisfying {eq}`markovpropd`\n",
    "and $X_0 \\sim \\psi$, the restriction $(X_0, \\ldots, X_n)$ has joint\n",
    "distribution $\\mathbf P_\\psi^n$.\n",
    "\n",
    "This is a solved exercise below.\n",
    "\n",
    "The last remaining step is to show that the family $(\\mathbf P_\\psi^n)$ defined at each $n \\in \\mathbb N$ extends uniquely to a distribution $\\mathbf P_\\psi$ over the infinite\n",
    "sequences in $S^\\infty$.\n",
    "\n",
    "That this is true follows from a well known [theorem of Kolmogorov](https://en.wikipedia.org/wiki/Kolmogorov_extension_theorem).\n",
    "\n",
    "Hence $P$ defines the joint distribution $\\mathbf P_\\psi$ when paired with any initial condition $\\psi$.\n",
    "\n",
    "\n",
    "\n",
    "### Extending to Countable State Spaces\n",
    "\n",
    "When $S$ is infinite, we cannot view $P$ as a matrix.  \n",
    "\n",
    "Instead, we introduce the notion of a **Markov kernel** on $S$, which is a function\n",
    "$P$ from $S \\times S$ to $\\mathbb R_+$ satisfying\n",
    "\n",
    "$$\n",
    "    \\sum_y P(x, y) = 1 \n",
    "    \\text{ for all } x \\in S\n",
    "$$\n",
    "\n",
    "This is a natural extension of matrices with nonnegative elements and unit row\n",
    "sums.\n",
    "\n",
    "The definition of a Markov chain $(X_t)_{t \\in \\mathbb Z_+}$ on $S$ with Markov kernel  $P$ is exactly as in {eq}`markovpropd`.\n",
    "\n",
    "Given Markov kernel $P$ and $\\phi \\in \\mathcal D$, we define $\\phi P$ by\n",
    "{eq}`update_rule`.\n",
    "    \n",
    "Then, as before, $\\phi P$ can be understood as the distribution of \n",
    "$X_{t+1}$ when $X_t$ has distribution $\\phi$.\n",
    "\n",
    "The function $\\phi P$ is in $\\mathcal D$, since, by {eq}`update_rule`, it is\n",
    "nonnegative and\n",
    "\n",
    "$$\n",
    "    \\sum_y (\\phi P)(y) \n",
    "    = \\sum_y \\sum_x P(x, y) \\phi(x)\n",
    "    = \\sum_x \\sum_y P(x, y) \\phi(x)\n",
    "    = \\sum_x \\phi(x)\n",
    "    = 1\n",
    "$$ \n",
    "\n",
    "Swapping the order of infinite sums is justified here by the fact that all\n",
    "elements are nonnegative (a version of Tonelli's theorem).\n",
    "\n",
    "We can take products of Markov kernels that are analogous to matrix products.\n",
    "\n",
    "In particular, if $P$ and $Q$ are Markov kernels on $S$, then, for $(x, y)$ in $S\n",
    "\\times S$,\n",
    "\n",
    "$$\n",
    "    (P Q)(x, y) := \\sum_z P(x, z) Q(z, y)\n",
    "$$ (kernprod)\n",
    "\n",
    "It is not difficult to check that the product $P Q$ is again a Markov kernel on $S$.\n",
    "\n",
    "The operation {eq}`kernprod` is analogous to matrix multiplication, so that\n",
    "elements of $P^k$, the $k$-th product of $P$ with itself, retain the finite\n",
    "state interpretation of $k$ step transition probabilities.\n",
    "\n",
    "For example, we have\n",
    "\n",
    "$$\n",
    "    P^k(x, y) \n",
    "    = (P^{k-j} P^j)(x, y) = \\sum_z P^{k-j}(x, z) P^j(z, y)\n",
    "$$ (kernprodk)\n",
    "\n",
    "which is a version of the discrete time Chapman-Kolmogorov equation.\n",
    "\n",
    "Equation {eq}`kernprodk` can be obtained from the law of total probability: if\n",
    "$(X_t)$ is a Markov chain with Markov kernel $P$ and initial condition $X_0 =\n",
    "x$, then \n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_k = y\\}\n",
    "    = \\sum_z \\mathbb P\\{X_k = y \\,|\\, X_j=z\\} \\mathbb P\\{X_j=z\\}\n",
    "$$\n",
    "\n",
    "\n",
    "All of the {ref}`preceding discussion <jdfin>` on the connection between $P$\n",
    "and the joint distribution of $(X_t)$ when $S$ is finite carries over \n",
    "to the current setting.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### The Continuous Time Case\n",
    "\n",
    "A **continuous time stochastic process** on $S$ is a collection $(X_t)$ of $S$-valued\n",
    "random variables $X_t$ defined on a common probability space and indexed by $t\n",
    "\\in \\mathbb R_+$.\n",
    "\n",
    "Let $I$ be the Markov kernel on $S$ defined by $I(x,y) = \\mathbb 1\\{x = y\\}$.\n",
    "\n",
    "A **transition semigroup** is a family $(P_t)$ of Markov kernels\n",
    "on $S$ satisfying $P_0 = I$ and\n",
    "\n",
    "$$\n",
    "    P_{s + t} = P_s P_t\n",
    "    \\qquad (s, t \\geq 0)\n",
    "$$ (chapkol_ct)\n",
    "\n",
    "The interpretation of $P_t(x, y)$ is the probability of moving from state $x$\n",
    "to state $y$ in $t$ units of time.\n",
    "\n",
    "Equation {eq}`chapkol_ct`, which is known as the semigroup property of\n",
    "$(P_t)$, is another version of the Chapman-Kolmogorov equation.\n",
    "\n",
    "This becomes clearer if we write it more explicitly as\n",
    "\n",
    "$$\n",
    "    P_{s+t}(x, y) \n",
    "    = \\sum_z P_s(x, z) P_t(z, y)\n",
    "$$ (chapkol_ct2)\n",
    "\n",
    "A stochastic process $(X_t)$ is called a (time homogeneous) **Markov process** on $S$\n",
    "with transition semigroup $(P_t)$ if\n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_{s + t} = y \\,|\\, \\mathcal F_s \\}\n",
    "    = P_t (X_s, y)\n",
    "$$ (markovprop)\n",
    "\n",
    "with probability one for all $y \\in S$ and $s, t \\geq 0$.\n",
    "\n",
    "Here $\\mathcal F_s$ is the history $(X_r)_{r \\leq s}$ of the process up until\n",
    "time $s$.\n",
    "\n",
    "If you are an economist you might call $\\mathcal F_s$ the \"information set\" at time\n",
    "$s$.\n",
    "\n",
    "If you are familiar with measure theory, you can understand $\\mathcal F_s$ as\n",
    "the $\\sigma$-algebra generated by $(X_r)_{r \\leq s}$.\n",
    "\n",
    "\n",
    "Analogous to the discrete time case, the joint\n",
    "distribution of $(X_t)$ is determined by its transition semigroup plus an\n",
    "initial condition.\n",
    "\n",
    "To prove this, one first builds finite dimensional distributions using\n",
    "expressions similar to {eq}`mathjointd`.\n",
    "\n",
    "Next the Kolmogorov extension theorem is applied, similar to the discrete time case\n",
    "(see, e.g., Corollary 6.4 of {cite}`le2016brownian`).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Example: Poisson Processes\n",
    "\n",
    "The Poisson process discussed in our {doc}`previous lecture <poisson>` is a\n",
    "Markov process on state space $\\mathbb Z_+$.\n",
    "\n",
    "To obtain the transition semigroup, we observe that, for $k \\geq j$,\n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{N_{s + t} = k \\,|\\, N_s = j\\}\n",
    "    = \\mathbb P\\{N_{s + t} - N_s = k - j \\,|\\, N_s = j\\}\n",
    "    = \\mathbb P\\{N_{s + t} - N_s = k - j\\}\n",
    "$$\n",
    "\n",
    "where the last step is due to independence of increments.\n",
    "\n",
    "From stationarity of increments we have\n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{N_{s + t} - N_s = k - j\\}\n",
    "    = \\mathbb P\\{N_t = k - j\\}\n",
    "    = e^{-\\lambda t} \\frac{ (\\lambda t)^{k-j} }{(k-j)!}\n",
    "$$\n",
    "\n",
    "In summary, the transition semigroup is\n",
    "\n",
    "$$\n",
    "    P_t(j, k) \n",
    "    = e^{-\\lambda t} \\frac{ (\\lambda t)^{k-j} }{(k-j)!}  \n",
    "$$ (poissemi)\n",
    "\n",
    "whenever $j \\leq k$ and $P_t(j, k) = 0$ otherwise.\n",
    "\n",
    "This chain of equalities was obtained with $N_s = j$ for arbitrary $j$, so we\n",
    "can replace $j$ with $N_s$ in {eq}`poissemi` to verify the Markov property {eq}`markovprop` for the Poisson process.\n",
    "\n",
    "Under {eq}`poissemi`, each $P_t$ is a Markov kernel and $(P_t)$ is a\n",
    "transition semigroup.\n",
    "\n",
    "The proof of the semigroup property is a solved exercise below.\n",
    "\n",
    "(In {eq}`poissemi` we use the convention that $0^0 = 1$, which leads to $P_0 = I$.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Example: Failure of the Markov Property\n",
    "\n",
    "Let's look at how the Markov property can fail, via an intuitive rather than\n",
    "formal discussion.\n",
    "\n",
    "Let $(X_t)$ be a continuous time stochastic process with state space $S = \\{0, 1\\}$.\n",
    "\n",
    "The process starts at $0$ and updates at follows:\n",
    "\n",
    "1. Draw $W$ independently from a fixed Pareto distribution.\n",
    "1. Hold $(X_t)$ in its current state for $W$ units of time and then switch\n",
    "    to the other state.\n",
    "1. Go to step 1.\n",
    "\n",
    "What is the probability that $X_{s+h} = i$ given both the history $(X_r)_{r \\leq s}$ and current information $X_s = i$?\n",
    "\n",
    "If $h$ is small, then this is close to the\n",
    "probability that there are zero switches over the time interval $(s, s+h]$.\n",
    "\n",
    "To calculate this probability, it would be helpful to know how long the\n",
    "state has been at current state $i$.\n",
    "\n",
    "This is because the Pareto distribution {ref}`is not memoryless <fail_mem>`.\n",
    "\n",
    "(With a Pareto distribution, if we know that $X_t$ has been at $i$ for a long\n",
    "time, then a switch in the near future becomes more likely.)\n",
    "\n",
    "As a result, the history prior to $X_s$ is useful for predicting $X_{s+h}$,\n",
    "even when we know $X_s$.\n",
    "\n",
    "Thus, the Markov property fails.\n",
    "\n",
    "\n",
    "\n",
    "### Restrictions Imposed by the Markov Property\n",
    "\n",
    "From the discussion above, we see that, for continuous time Markov chains,\n",
    "the length of time between jumps must be memoryless.\n",
    "\n",
    "Recall that the {ref}`only <exp_unique>` memoryless distribution supported on $\\mathbb R_+$ is the exponential distribution.\n",
    "\n",
    "[XX why isn't this link working??]\n",
    "\n",
    "Hence, a continuous time Markov chain waits at states for an\n",
    "exponential amount of time and then jumps.\n",
    "\n",
    "The way that the new state is chosen must also satisfy the Markov property,\n",
    "which adds another restriction. \n",
    "\n",
    "In summary, we already understand the following about continuous time Markov chains:\n",
    "\n",
    "1. Holding times are independent exponential draws.\n",
    "1. New states are chosen in a ``Markovian'' way, independent of the past given the current state.\n",
    "\n",
    "We just need to clarify the details in these steps to have a complete description.\n",
    "\n",
    "\n",
    "We start this process with an example.\n",
    "\n",
    "\n",
    "(inventory_dynam)=\n",
    "## A Model of Inventory Dynamics\n",
    "\n",
    "\n",
    "Let $X_t$ be the inventory of a firm at time $t$, taking values in the\n",
    "integers $0, 1, \\ldots, b$.\n",
    "\n",
    "If $X_t > 0$, then a customer arrives after $W$\n",
    "units of time, where $W \\sim E(\\lambda)$ for some fixed $\\lambda > 0$.\n",
    "\n",
    "Upon arrival, each customer purchases $\\min\\{U, X_t\\}$ units, where $U$ is an\n",
    "IID draw from the geometric distribution started at 1 rather than 0:\n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{U = k\\} = (1-\\alpha)^{k-1} \\alpha\n",
    "    \\qquad (k = 1, 2, \\ldots, \\; \\alpha \\in (0, 1))\n",
    "$$\n",
    "\n",
    "If $X_t = 0$, then no customers arrive and the firm places an order for $b$ units.\n",
    "\n",
    "The order arrives after a delay of $D$ units of time, where $D \\sim E(\\lambda)$.\n",
    "\n",
    "(We use the same $\\lambda$ here just for convenience, to simplify the exposition.)\n",
    "\n",
    "### Representation\n",
    "\n",
    "The inventory process jumps to a new value either when a new customer arrives\n",
    "or when new stock arrives.\n",
    "\n",
    "Between these arrival times it is constant.\n",
    "\n",
    "Hence, to track $X_t$, it is enough to track the jump times and the new values\n",
    "taken at the jumps.\n",
    "\n",
    "In what follows, we denote the jump times by $\\{J_k\\}$ and the values at jumps\n",
    "by $\\{Y_k\\}$.\n",
    "\n",
    "Then we construct the state process via\n",
    "\n",
    "$$\n",
    "    X_t = \\sum_{k \\geq 0} Y_k \\mathbb 1\\{J_k \\leq t < J_{k+1}\\}\n",
    "    \\qquad (t \\geq 0)\n",
    "$$ (xfromy)\n",
    "\n",
    "\n",
    "\n",
    "### Simulation\n",
    "\n",
    "Let's simulate this process, starting at $X_0 = 0$.\n",
    "\n",
    "As above,\n",
    "\n",
    "* $J_k$ is the time of the $k$-th jump (up or down) in inventory.\n",
    "* $Y_k$ is the size of the inventory after the $k$-th jump.\n",
    "* $(X_t)$ is defined from these objects via {eq}`xfromy`.\n",
    "\n",
    "Here's a function that generates and returns one path $t \\mapsto X_t$.\n",
    "\n",
    "(We are not aiming for computational efficiency at this stage.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_path(T=10, seed=123, λ=0.5, α=0.7, b=10):\n",
    "    \"\"\"\n",
    "    Generate a path for inventory starting at b, up to time T.\n",
    "\n",
    "    Return the path as a function X(t) constructed from (J_k) and (Y_k).\n",
    "    \"\"\"\n",
    "\n",
    "    J, Y = 0, b\n",
    "    J_vals, Y_vals = [J], [Y]\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    while True:\n",
    "        W = np.random.exponential(scale=1/λ)  # W ~ E(λ)\n",
    "        J += W\n",
    "        J_vals.append(J)\n",
    "        if J >= T:\n",
    "            break\n",
    "        else:\n",
    "            # Update Y\n",
    "            if Y == 0:\n",
    "                Y = b\n",
    "            else:\n",
    "                U = np.random.geometric(α)\n",
    "                Y = Y - min(Y, U)\n",
    "        Y_vals.append(Y)\n",
    "    \n",
    "    Y_vals = np.array(Y_vals)\n",
    "    J_vals = np.array(J_vals)\n",
    "\n",
    "    def X(t):\n",
    "        if t == 0.0:\n",
    "            return Y_vals[0]\n",
    "        else:\n",
    "            k = np.searchsorted(J_vals, t)\n",
    "            return Y_vals[k-1]\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the process $(X_t)$ using the ``step`` method of ``ax``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 20\n",
    "X = sim_path(T=T)\n",
    "\n",
    "grid = np.linspace(0, T, 100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.step(grid, [X(t) for t in grid], label=\"$X_t$\")\n",
    "\n",
    "ax.set(xlabel=\"time\", ylabel=\"inventory\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, inventory falls and then jumps back up to $b$.\n",
    "\n",
    "\n",
    "\n",
    "### The Embedded Jump Chain\n",
    "\n",
    "In models such as the one described above, the embedded discrete time \n",
    "process $(Y_n)$ is called the \"embedded jump chain\".\n",
    "\n",
    "It is easy to see that $(Y_n)$ is discrete time finite state Markov chain.\n",
    "\n",
    "Its Markov matrix $K$ is\n",
    "given by  $K(x, y) = \\mathbb 1\\{y=b\\}$ when $x=0$ and,  when $0 < x \\leq b$, \n",
    "\n",
    "$$\n",
    "    K(x, y)\n",
    "    =\n",
    "    \\begin{cases}\n",
    "    \\mathbb 0 & \\text{ if }  y \\geq x\n",
    "    \\\\\n",
    "    \\mathbb P\\{x - U = y\\} = (1-\\alpha)^{x-y-1} \\alpha \n",
    "        & \\text{ if } 0 < y < x\n",
    "    \\\\\n",
    "    \\mathbb P\\{U \\geq x\\} = (1-\\alpha)^{x-1}\n",
    "        & \\text{ if } y = 0\n",
    "    \\end{cases}\n",
    "$$ (ijumpkern)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Markov Property\n",
    "\n",
    "The inventory model just described has the Markov property precisely because\n",
    "\n",
    "1. the jump chain $(Y_n)$ is Markov in discrete time and\n",
    "1. the holding times are independent exponential draws.\n",
    "\n",
    "Rather than providing more details on these points here, let us first describe\n",
    "a more general setting where the arguments will be clearer and more useful.\n",
    "\n",
    "\n",
    "\n",
    "## Jump Processes with Constant Rates\n",
    "\n",
    "The examples we have focused on so far are special cases of Markov processes\n",
    "with constant jump intensities.\n",
    "\n",
    "This processes turn out to be very representative (although the constant jump intensity will later be relaxed).\n",
    "\n",
    "Let's now summarize the model and its properties.\n",
    "\n",
    "\n",
    "### Construction\n",
    "\n",
    "The data for a Markov process on $S$ with constant jump rates are \n",
    "\n",
    "* a parameter $\\lambda > 0$ called the **jump rate**, which governs the jump\n",
    "  intensities and\n",
    "* a Markov kernel $K$ on $S$, called the **jump kernel**.\n",
    "\n",
    "To run the process we also need an initial condition $\\psi \\in \\mathcal D$.\n",
    "\n",
    "The process $(X_t)$ is constructed by holding at each state for an\n",
    "exponential amount of time, with rate $\\lambda$, and then updating to a\n",
    "new state via $K$.\n",
    "\n",
    "In more detail, the construction is\n",
    "\n",
    "1. draw $Y_0$ from $\\psi$ \n",
    "1. set $n = 1$ and $J_0 = 0$\n",
    "1. draw $W_n$ from Exp$(\\lambda)$ and set $J_n = J_{n-1} + W_n$\n",
    "1. set $X_t = Y_{n-1}$ for all $t$ such that $J_{n-1} \\leq t < J_n$.\n",
    "1. draw $Y_n$ from $K(Y_{n-1}, \\cdot)$ \n",
    "1. set $n = n+1$ and go to step 3.\n",
    "\n",
    "An alternative, more parsimonious way to express the same process is to take \n",
    "\n",
    "* $(N_t)$ to be a Poisson process with rate $\\lambda$ and\n",
    "* $(Y_n)$ to be a discrete time Markov chain with kernel $K$\n",
    "\n",
    "and then set\n",
    "\n",
    "$$\n",
    "    X_t := Y_{N_t} \\text{ for all } t \\geq 0\n",
    "$$\n",
    "\n",
    "As before, the discrete time process $(Y_n)$ is called the **embedded jump chain**.\n",
    "\n",
    "(Not to be confused with $(X_t)$, which is often called a \"jump process\" due\n",
    "to the fact that it changes states with jumps.)\n",
    "\n",
    "The draws $(W_n)$ are called the **wait times** or **holding times**.\n",
    "\n",
    "\n",
    "### Examples\n",
    "\n",
    "The Poisson process with rate $\\lambda$ is a jump process on $S = \\mathbb Z_+$.\n",
    "\n",
    "The holding times are obviously exponential with constant rate $\\lambda$.\n",
    "\n",
    "The jump kernel is just $K(i, j) = \\mathbb 1\\{j = i+1\\}$, so that the state\n",
    "jumps up by one at every $J_n$.\n",
    "\n",
    "The inventory model is also a jump process with constant rate $\\lambda$, this\n",
    "time on $S = \\{0, 1, \\ldots, b\\}$.\n",
    "\n",
    "The jump kernel (or matrix in this case) was given in {eq}`ijumpkern`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Markov Property\n",
    "\n",
    "Let's show that the jump process $(X_t)$ constructed above satisfies the\n",
    "Markov property, and obtain the transition semigroup at the same time.\n",
    "\n",
    "We will use two facts:\n",
    "\n",
    "* the jump chain $(Y_n)$ has the Markov property in discrete\n",
    "  time and\n",
    "* the Poisson process has stationary independent increments.\n",
    "\n",
    "From these facts it is intuitive that the distribution of $X_{t+s}$ given\n",
    "the whole history $\\mathcal F_s = \\{ (N_r)_{r \\leq s}, (Y_n)_{n \\leq N_s} \\}$\n",
    "depends only on $X_s$.\n",
    "\n",
    "Indeed, if we know $X_s$, then we can simply {ref}`restart <restart_prop>` the\n",
    "Poisson process from $N_s$ and then update the jump chain using $K$ each time a\n",
    "jump occurs, starting from $X_s$.\n",
    "\n",
    "Let's write this more mathematically.\n",
    "\n",
    "Fixing $y \\in S$ and $s, t \\geq 0$, we have\n",
    "\n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_{s + t} = y \\,|\\, \\mathcal F_s \\}\n",
    "      = \\mathbb P\\{Y_{N_{s + t}} = y \\,|\\, \\mathcal F_s \\}\n",
    "      = \\mathbb P\\{Y_{N_s + N_{s + t} - N_s} = y \\,|\\, \\mathcal F_s \\}\n",
    "$$\n",
    "\n",
    "{ref}`Recalling <restart_prop>` that $N_{s + t} - N_s$ is Poisson distributed with rate $t \\lambda$, independent of the history $\\mathcal F_s$, we can write the display above as \n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_{s + t} = y \\,|\\, \\mathcal F_s \\}\n",
    "    =\n",
    "    \\sum_{k \\geq 0}\n",
    "    \\mathbb P\\{Y_{N_s + k} = y \\,|\\, \\mathcal F_s \\}\n",
    "       \\frac{(t \\lambda )^k}{k!} e^{-t \\lambda}\n",
    "$$\n",
    "\n",
    "Because the jump chain is Markov with kernel $K$, we can simplify further to\n",
    "\n",
    "\n",
    "$$\n",
    "    \\mathbb P\\{X_{s + t} = y \\,|\\, \\mathcal F_s \\}\n",
    "    = \\sum_{k \\geq 0}\n",
    "    K^k(Y_{N_s}, y) \\frac{(t \\lambda )^k}{k!} e^{-t \\lambda}\n",
    "    = K^k(X_s, y) \\frac{(t \\lambda )^k}{k!} e^{-t \\lambda}\n",
    "$$\n",
    "\n",
    "Since the expression above depends only on $X_s$,\n",
    "we have proved that $(X_t)$ has the Markov property.\n",
    "\n",
    "\n",
    "(consjumptransemi)=\n",
    "### Transition Semigroup\n",
    "\n",
    "The transition semigroup can be obtained from our final result, conditioning\n",
    "on $X_s = x$ to get\n",
    "\n",
    "$$\n",
    "    P^t(x, y) = \\mathbb P\\{X_{s + t} = y \\,|\\, X_s = x \\}\n",
    "    = e^{-t \\lambda} \\sum_{k \\geq 0}\n",
    "        K^k(x, y) \\frac{(t \\lambda )^k}{k!} \n",
    "$$\n",
    "\n",
    "If $S$ is finite, we can write this in matrix form and use the definition of\n",
    "the [matrix exponential](https://en.wikipedia.org/wiki/Matrix_exponential) to\n",
    "get\n",
    "\n",
    "$$\n",
    "    P^t \n",
    "    = e^{-t \\lambda}\n",
    "        \\sum_{k \\geq 0}\n",
    "        \\frac{(t \\lambda K)^k}{k!} \n",
    "    = e^{-t \\lambda} e^{t \\lambda K}\n",
    "    = e^{t \\lambda (K - I)}\n",
    "$$\n",
    "\n",
    "This is a simple and elegant representation of the transition semigroup that\n",
    "makes it easy to understand and analyze distribution dynamics.\n",
    "\n",
    "For example, if $X_0$ has distribution $\\psi$, then $X_t$ has distribution\n",
    "\n",
    "$$\n",
    "    \\psi P_t = \\psi e^{t \\lambda (K - I)}\n",
    "$$ (distflowconst)\n",
    "\n",
    "We just need to plug in $\\lambda$ and $K$ to obtain the entire flow $t \\mapsto \\psi P_t$.\n",
    "\n",
    "We will soon extend this representation to the case where $S$ is infinite.\n",
    "\n",
    "\n",
    "(invdistflows)=\n",
    "## Distribution Flows for the Inventory Model\n",
    "\n",
    "Let's apply these ideas to the inventory model described above.\n",
    "\n",
    "We fix \n",
    "\n",
    "* the parameters $\\alpha$, $b$ and $\\lambda$ in the inventory model and\n",
    "* an initial condition $X_0 \\sim \\psi_0$, where $\\psi_0$ is an arbitrary\n",
    "distribution on $S$.\n",
    "\n",
    "The state $S$ is set to $\\{0, \\ldots, b\\}$ and the kernel $K$ is defined by\n",
    "{eq}`ijumpkern`.\n",
    "\n",
    "Now we run time forward.\n",
    "\n",
    "We are interesting in computing the flow of distributions $t \\mapsto \\psi_t$,\n",
    "where $\\psi_t$ is the distribution of $X_t$.\n",
    "\n",
    "According to the theory developed above, we have two options:\n",
    "\n",
    "Option 1 is to use simulation.\n",
    "\n",
    "The first step is to simulate many independent observations the process $(X_t^m)_{m=1}^M$.\n",
    "\n",
    "(Here $m$ indicates simulation number $m$, which you might think of as the outcome\n",
    "for firm $m$.)\n",
    "\n",
    "Next, for any given $t$, we define $\\hat \\psi_t \\in \\mathcal D$ as the\n",
    "histogram of observations at time $t$, or, equivalently the cross-sectional\n",
    "distribution at $t$:\n",
    "\n",
    "$$\n",
    "    \\hat \\psi_t(x) := \\frac{1}{M} \\sum_{m=1}^M \\mathbb 1\\{X_t = x\\}\n",
    "    \\qquad (x \\in S)\n",
    "$$\n",
    "\n",
    "Then $\\hat \\psi_t(x)$ will be close to $\\mathbb P\\{X_t = x\\}$ by the law of\n",
    "large numbers.\n",
    "\n",
    "In other words, in the limit we recover $\\psi_t$.\n",
    "\n",
    "\n",
    "Option 2 is to insert the parameters into the right hand side of {eq}`distflowconst`\n",
    "and compute $\\psi_t$ as $\\psi_0 P_t$.\n",
    "\n",
    "Let's try option 2, with $\\alpha = 0.6$, $\\lambda = 0.5$ and $b=10$.\n",
    "\n",
    "For the initial distribution we pick a binomial distribution.\n",
    "\n",
    "Since we cannot compute the entire uncountable flow $t \\mapsto \\psi_t$, we\n",
    "iterate forward 200 steps at time increments $h=0.1$.\n",
    "\n",
    "In the figure below, hot colors indicate initial conditions and early dates (so that the\n",
    "distribution \"cools\" over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    α = 0.6\n",
    "    λ = 0.5\n",
    "    b = 10\n",
    "    n = b + 1\n",
    "    states = np.arange(n)\n",
    "    I = np.identity(n)\n",
    "\n",
    "    K = np.zeros((n, n))\n",
    "    K[0, -1] = 1\n",
    "    for i in range(1, n):\n",
    "        for j in range(0, i):\n",
    "            if j == 0:\n",
    "                K[i, j] = (1 - α)**(i-1)\n",
    "            else:\n",
    "                K[i, j] = α * (1 - α)**(i-j-1)\n",
    "\n",
    "\n",
    "    def P_t(ψ, t):\n",
    "        return ψ @ expm(t * λ * (K - I))\n",
    "\n",
    "    def plot_distribution_dynamics(ax, ψ_0, steps=200, step_size=0.1):\n",
    "        ψ = ψ_0\n",
    "        t = 0.0\n",
    "        colors = cm.jet_r(np.linspace(0.0, 1, steps))\n",
    "\n",
    "        for i in range(steps):\n",
    "            ax.bar(states, ψ, zs=t, zdir='y', \n",
    "                color=colors[i], alpha=0.8, width=0.4)\n",
    "            ψ = P_t(ψ, t=step_size)\n",
    "            t += step_size\n",
    "\n",
    "        ax.set_xlabel('inventory')\n",
    "        ax.set_ylabel('$t$')\n",
    "\n",
    "\n",
    "    ψ_0 = binom.pmf(states, n, 0.25)\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    plot_distribution_dynamics(ax, ψ_0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercises below you are asked to implement option 1 and check that the\n",
    "figure looks the same.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Consider the binary (Bernoulli) distribution where outcomes $0$ and $1$ each have\n",
    "probability $0.5$.\n",
    "\n",
    "Construct two different random variables with this distribution.\n",
    "\n",
    "\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "Show by direct calculation that the Poisson kernels $(P_t)$ defined in \n",
    "{eq}`poissemi` satisfy the semigroup property {eq}`chapkol_ct2`.\n",
    "\n",
    "Hints\n",
    "\n",
    "* Recall that $P_t(j, k) = 0$ whenever $j > k$.\n",
    "* Consider using the [binomial\n",
    "  formula](https://en.wikipedia.org/wiki/Binomial_theorem).\n",
    "\n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "Consider the distribution over $S^{n+1}$ previously shown in {eq}`mathjointd`, which is\n",
    "\n",
    "$$\n",
    "    \\mathbf P_\\psi^n(x_0, x_1, \\ldots, x_n)\n",
    "        = \\psi(x_0)\n",
    "        P(x_0, x_1)\n",
    "        \\times \\cdots \\times\n",
    "        P(x_{n-1}, x_n)\n",
    "$$ \n",
    "\n",
    "Show that, for any Markov chain $(X_t)$ satisfying {eq}`markovpropd`\n",
    "and $X_0 \\sim \\psi$, the restriction $(X_0, \\ldots, X_n)$ has joint\n",
    "distribution $\\mathbf P_\\psi^n$.\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "Replicate, as best you can, the figure produced from the {ref}`discussion on distribution flows <invdistflows>`, this time using option 1.\n",
    "\n",
    "You will need to use a suitably large sample.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Solutions\n",
    "\n",
    "### Solution to Exercise 1\n",
    "\n",
    "This is easy.\n",
    "\n",
    "One example is to take $U$ to be uniform on $(0, 1)$ and set $X=0$ if $U <\n",
    "0.5$ and $1$ otherwise.\n",
    "\n",
    "Then $X$ has the desired distribution.\n",
    "\n",
    "Alternatively, we could take $Z$ to be standard normal and set $X=0$ if $Z <\n",
    "0$ and $1$ otherwise.\n",
    " \n",
    "\n",
    "### Solution to Exercise 2\n",
    "\n",
    "Fixing $s, t \\in \\mathbb R_+$ and $j \\leq k$, we have \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\sum_{i \\geq 0} P_s(j, i) P_t(i, k)\n",
    "    & = \n",
    "    e^{-\\lambda (s+t)} \n",
    "    \\sum_{j \\leq i \\leq k}\n",
    "        \\frac{ (\\lambda s)^{i-j} }{(i-j)!}  \n",
    "        \\frac{ (\\lambda t)^{k-i} }{(k-i)!}  \n",
    "    \\\\\n",
    "    & = \n",
    "    e^{-\\lambda (s+t)} \\lambda^{k-j}\n",
    "    \\sum_{0 \\leq \\ell \\leq k-j}\n",
    "        \\frac{  s^\\ell }{\\ell!}  \n",
    "        \\frac{ t^{k-j - \\ell} }{(k-j - \\ell)!}  \n",
    "    \\\\\n",
    "    & = \n",
    "    e^{-\\lambda (s+t)} \\lambda^{k-j}\n",
    "    \\sum_{0 \\leq \\ell \\leq k-j}\n",
    "        \\binom{k-j}{\\ell}\n",
    "        \\frac{s^\\ell t^{k-j - \\ell}}{(k-j)!}  \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Applying the binomial formula, we can write this as \n",
    "\n",
    "$$\n",
    "    \\sum_{i \\geq 0} P_s(j, i) P_t(i, k)\n",
    "    =\n",
    "    e^{-\\lambda (s+t)} \n",
    "    \\frac{(\\lambda (s + t))^{k-j}}{(k-j)!}\n",
    "    = P_{s+t}(j, k)\n",
    "$$\n",
    "\n",
    "Hence {eq}`chapkol_ct2` holds, and the semigroup property is satisfied.\n",
    "\n",
    "\n",
    "### Solution to Exercise 3 \n",
    "\n",
    "Let $(X_t)$ be a Markov chain satisfying {eq}`markovpropd` and $X_0 \\sim \\psi$.\n",
    "\n",
    "When $n=0$, we have $\\mathbf P_\\psi^n = \\mathbf P_\\psi^0 = \\psi$, and this\n",
    "agrees with the distribution of the restriction $(X_0, \\ldots, X_n) = (X_0)$.\n",
    "\n",
    "Now suppose the same is true at arbitrary $n-1$, in the sense that\n",
    "the distribution of $(X_0, \\ldots, X_{n-1})$ is equal to $\\mathbf P_\\psi^{n-1}$ as\n",
    "defined above.\n",
    "\n",
    "Then \n",
    "\n",
    "$$\n",
    "    \\mathbb P \\{X_0 = x_0, \\ldots, X_n = x_n\\}\n",
    "    = \\mathbb P \\{X_n = x_n \\,|\\, X_0 = x_0, \\ldots, X_{n-1} = x_{n-1}  \\}\n",
    "    \\\\\n",
    "        \\times \\mathbb P \\{X_0 = x_0, \\ldots, X_{n-1} = x_{n-1}\\}\n",
    "$$\n",
    "\n",
    "From the Markov property and the induction hypothesis, the right hand side is\n",
    "\n",
    "$$\n",
    "    P (x_{n-1}, x_n )\n",
    "    \\mathbf P_\\psi^n(x_0, x_1, \\ldots, x_{n-1})\n",
    "    =\n",
    "        P (x_n, x_{n+1} )\n",
    "        \\psi(x_0)\n",
    "        P(x_0, x_1)\n",
    "        \\times \\cdots \\times\n",
    "        P(x_{n-1}, x_{n-1})\n",
    "$$\n",
    "\n",
    "The last expression equals $\\mathbf P_\\psi^n$, which concludes the proof.\n",
    "\n",
    "\n",
    "### Solution to Exercise 4 \n",
    "\n",
    "[To be added.]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
